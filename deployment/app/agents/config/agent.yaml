agents:
  llm_chat:
    provider: vllm
    model_name: SeaLLMs/SeaLLMs-v3-7B-Chat
    type: chat
    temperature: 0.8
    max_tokens: 1024
    base_url: http://79.117.27.229:22074/v1
    api_key: b826f8ae19f62e8d657ca6d5bd5de590130c2dd49a06d8dfa9486a5e05f798e5

  llm_reasoning:
    provider: ollama
    model_name: llama3.2:1b
    type: reasoning
    temperature: 0.2
    max_tokens: 1024
    base_url: http://localhost:11434
